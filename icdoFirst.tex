\chapter{\ac{icdo} classification}
\label{ch:icdoFirst}
\subsection{Dataset}
\label{sec:dataset}
We collected a set of $1\,592\,385$ anatomopathological exam results
from Tuscany region in the period 2004-2013. About $6\%$
of these records refer to a positive tumor
diagnosis and have topological and morphological ICD-O3 labels,
determined by tumor registry experts. Other reports are associated
with non-cancerous tissues and with unlabeled records. When multiple
pathological records for the
same patient existed for the same tumor, experts selected the most
informative report in order to assign the ICD-O3 code to that tumor
case, leaving a set of $94\,524$ labeled tumor cases.

Histological exam records consist of three free-text fields (not all
of them always filled-in), reporting tissue macroscopy, diagnosis,
and, in some cases, the patient's anamnesis. We found that field
semantics was not always used consistently and that the amount of
provided details varied significantly from extremely synthetic to very
detailed assessments of the morphology and the diagnosis. Field length
ranged from $0$ to $1\,368$ words, with first quartile, median and
third quartile respectively 34, 62, 134. For these reasons we merged
the three text fields
into a single text document, did not apply any conflation (except for
case normalization) kept punctuation.


% The data used in this work comes from the \ac{rtt}. It is composed of
% a list of
% neoplasm records, for each one is specified:
% \begin{itemize}
%     \item a series of administrative variables, e.g.\ the date of incidence, the hospital;
%     \item \ac{icdo} codes, both first and third editions, for topography
%     and morphology;
%     \item other clinical variables, e.g.\ \emph{Gleason}, \emph{Clark}, \emph{Dukes}
%     scores.
% \end{itemize}
% \ac{icdo} codes inside neoplasm records are assigned by
% \ac{rtt} personnel, thus they can be considered reliable and used as
% ground truth for the learning models.

% Furthermore, there is an histology table containing records resulting
% from microscopy exams. Each record contains three free-text
% fields, one for the macroscopy, one for the diagnosis, and one for
% other information. Besides, the histology table contains \ac{icdo} and
% \ac{icdo3} codes resulting from the application of the preexisting
% rule-based classifier. We employ those codes in order to assess the
% existing
% system, and use it as a baseline.

% The neoplasm and histology tables can be joined using a
% neoplasm identifier. Thus connecting the text
% fields with the true \ac{icdo} codes.

% The data set is composed of $309\,852$ neoplasm and $1\,592\,385$
% histology records. When joined, the resulting records are $94\,524$.

% There are neoplasm cases
% without a related histology exam because \ac{rtt} uses also other
% sources to collect tumor cases, e.g.\ \acp{hdr}, death certificates,
% etc\dots. There are also histology exams without a related neoplasm
% case because not always an histology results in a tumor case.

% \fixme{We noticed that the differences between the text fields of the
% histology records are not pronounced. Thus we considered them as
% a single field}
% \footnote{In order to build the word vectors we considered the
% fields independently.}.

\subsection{Classifiers}
We realized four multiclass classifiers for the
histological exams. Calling $X$ the distribution of texts, $Y^s$
of site, $Y^f$ of full site (site plus subsite), $Y^t$ of type, and
$Y^b$ of behavior:
\begin{description}
  \item[\site{}] estimates $P(Y^s|X)$;
  \item[\fullSite{}] estimates $P(Y^f|X)$;
  \item[\type{}] estimates $P(Y^t|X)$;
  \item[\behaviour{}] estimates $P(Y^b|X)$.
\end{description}

% The different tasks are not fully independent: obviously \fullSite{}
% classification depends on \site{} classification, but also \type{},
% \behaviour{} and \site{} can be interdependent. Many types of tumor are
% associated to a specific site, some types even indicates a
% specific behavior. For instance, \type{} $8253$
% corresponds to the definition of \emph{bronchio-alveolar carcinoma,
%   mucinous}, and it can be only malignant (\behaviour{} $3$) and located in
% bronchus and lungs (\site{} $34$). Thus, some configurations are impossible.

% Every task is a multiclass classification problem because every
% record is assigned to a single couple of \ac{icdo} codes,
% topographical and morphological.

% We considered the third \ac{icdo} version. There are
% $94\,061$ records with \ac{icdo3} codes.
The tasks have a variable number of represented classes, resumed in
\cref{fig:numClasses}.
\begin{table}
  \center
  \caption{Number of classes for different tasks.}
  \label{fig:numClasses}
  \begin{tabular}{|l|c|}
    \hline
    task & classes \\
    \hline
    \site{} & 70 \\
    \fullSite{} & 284 \\
    \type{} & 434 \\
    \behaviour{} & 5 \\
    \hline
  \end{tabular}
\end{table}
Moreover, data is not balanced. As visible in \cref{fig:classDist},
some classes are common, many are rare.
% In order to collect more than the
% $90\%$ of the 
% records it is sufficient to take the most frequent classes: $17$ over $70$
% for \site{}, $50$ over $284$ for \fullSite{},
% $44$ over $434$ for \type{}, and $2$ over $5$ for \behaviour{}
% classifications.
\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{img/classDist-icdo3-site.pdf}
  \includegraphics[width=0.45\textwidth]{img/classDist-icdo3-fullSite.pdf}
  \includegraphics[width=0.45\textwidth]{img/classDist-icdo3-type.pdf}
  \includegraphics[width=0.45\textwidth]{img/classDist-icdo3-behaviour.pdf}
  \caption{Documents in classes (ordered by
    frequency).}
  \label{fig:classDist}
\end{figure}

Frequency of words in text
respects the typical Zipf's distribution with few words that cover the
majority of text, and a long tail of infrequent words.
% The $85\%$ of
% the $9\,264\,143$ words in text is covered With $500$
% over a total of $35\,216$ distinct words. 

\subsection{Baselines}
\label{sec-baselines}
Most previous works in this area employed a bag-of-words
representation of textual documents
\cite{manning_introduction_2008}. In this approach, a document is 
described by a \textit{set} or a \textit{multiset} of words.
Multisets allow one to take into account the number of occurrences of
a word in the document. Vector representations of documents are easily
derived from bags-of-words. When using unigrams, the dimensionality of
each vector equals the size of the vocabulary in use. In the simplest
case, the vector $x$ representing a document has Boolean components
$x_j=1$ if and only if term $j$ appears in the document. A slightly more
informative representation, derived from multisets, is \ac{tfidf}
\cite{manning_introduction_2008}. In this case 
$x_j=n_j\log \frac{|D|}{|D_j|}$ where $n_j$ is the number of times
term $j$ occurs in the document, $|D|$ is the cardinality of the
data set, and $D_j$ is the set of documents containing term $j$. In
those representations, common terms receive a lower weight. An
alternative representation suggested in
\cite{martinez_information_2011} employed within-category frequencies
but only yielded modest improvements over \ac{tfidf} and thus we do not
use it in our baseline.

A more informative representation of documents can be obtained by
taking into account bigrams and trigrams, i.e.\ pairs or triplets or
terms that occur consecutively in a document. These representations
are suitable for large data sets and have been commonly employed in
other contexts.
% Explain how we used bigrams and trigrams

Bag-of-words representations (including those employing bigrams or
trigrams) enable the application of very simple text classifiers such
as \ac{nb} or \ac{svm} \cite{cortes-support-1995}. However, they
suffer two fundamental problems. First, the relative order of terms in
the documents is lost, making it impossible to take advantage of the
syntactic structure of the sentences. Second, distinct words have an
orthogonal representation even when they are semantically
close. Moreover the vast majority of the dataset, i.e. the unlabeled
records, remains unused with
this representation. These
limitations are addressed by the methods described in
\cref{sec:word-vectors}.

\subsection{Word Vectors}
\label{sec:word-vectors}
Many modern approaches to NLP take advantage of vector-space word
representations to solve specific tasks such as retrieval,
classification, named entity recognition or parsing. % Add citations
The use of word vectors eliminates the need for complex ontologies
like WordNet \cite{fellbaum-wordnet-1998}, that express various kinds of semantic relations among
words (such as synonymy, hypernymy, meronymy, etc). Word vectors are
typically constructed in such a way that analogies are directly
encoded in vector space. One often cited example of analogy is ``king
is to man as queen is to woman'', which should correspond to the
similarity in vector space~\cite{mikolov_linguistic_2013}:
$$
x_\mathit{king}-x_\mathit{man}+x_\mathit{woman} \approx x_\mathit{queen}.
$$
In a similar spirit, one could imagine the following vector space
similarity to occur in the oncology domain:
$$
x_\mathit{glioma}-x_\mathit{glia}+x_\mathit{connective} \approx
x_\mathit{fibroma}.
$$
\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{img/gloveGraph.pdf}
  \caption{Extract from constructed vector space. The Italian labels
    are \emph{grassa} for \emph{fat}, \emph{connettivi} for
    \emph{connectives}, \emph{ghiandole} for \emph{glands}.}
  \label{fig:gloveGraph}
\end{figure}

Most algorithms for obtaining word vectors are based on co-occurrences
in large text corpora. Co-occurrence can be measured either at the
word-document level (e.g.\ using latent semantic analysis) or at the
word-word level (e.g.\ using word2vec~\cite{mikolov_linguistic_2013}
or \ac{glove}~\cite{pennington_glove:_2014}). It is a common practice to
take advantage of pre-compiled libraries of word vectors trained on
several billion tokens extracted from various sources such as
Wikipedia, the English Gigaword 5, Common Crawl, or Twitter. These
libraries are generally conceived for general purpose applications and
are only available for the English language. Since our cancer registry
textual data is written in Italian and employs a very specific domain
terminology, we retrained word vectors from the almost 1.5 millions
unlabeled records described in Section~\ref{sec:dataset}. For this
purpose, we trained \ac{glove}~\cite{pennington_glove:_2014}. An
excerpt of the trained dataset is visible in \cref{fig:gloveGraph}.

The training process involves the construction of the
$n\times n$ triangular matrix $C$ of words co-occurrence, where $n$ is
the number of unique words $w_1,\dots,w_n$ inside the text\footnote{Possibly excluded the
  most and the least frequent terms.}. In order to do this, a window of
size $\omega$ slides
through the text. After the construction of $C$, \ac{glove} uses the
information contained in it to train a model that produces vector of
specific dimension $\nu$.

$\omega$, $\nu$, and the number of
training iterations $\eta$ are parameters of the method. 

\subsubsection{Use cases}
The different metrics are useful to assess models in different
situations. In case you need to retrieve records of a specific
cancer case from the register, MAPc assesses how
well the task is executed.
Conversely in case of an operator-assistance software, MAPs
assess how the correct classification
for a specific histological record is retrieved on top results. 

Cohen's kappa measures the agreement of automatic
and human annotators. Thus it is an indirect measure of the
classification correctness.

Precision and recall are two measures in trade off between them. The
former is more significant when you need a list of
correctly-classified records, at cost of not retrieving all of
them. The latter is more
meaningful when you need to retrieve the major number of cases at cost
of retrieving also some false positives. A peculiarity of the
automatic annotator is that you can change the threshold to support
higher precision or recall depending on the specific retrieving
task. Recall-precision
curves can be used to assess the correct threshold.

\section{Results}
\subsection{Models}\label{sec:models}
We realized five models:
\begin{description}
\item[\svm] a \ac{svm} trained on \ac{tfidf} representation of text
  using unigrams;
\item[\svmb] a \ac{svm} trained on \ac{tfidf} representation
  using unigrams and bigrams;
\item[\lstmng] a \ac{lstm} trained on \ac{tfidf} representation using
  bigrams;
\item[\lstmc] a mixed convolutional and \ac{lstm} model trained on
  \ac{glove} representation;
\item[\lstmb] a \ac{lstm} trained on \ac{glove} representation.
\end{description}

In models \svm{} and \svmb{} we used a \ac{tfidf}
representation ignoring terms present in less
than 3 documents or in
more than 30\% of the documents. 

In \lstmng{} we used a word embedding of $30$. The
embedding layer corresponds to a one-hot representation of the input
followed by a dense layer of $30$ neurons.

\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{img/gloveParameter.pdf}
  \caption{Accuracy top 1,5,10 and 15 for an intrinsic test with
    varying word vector dimension.}
  \label{fig:gloveParameter}
\end{figure}
In \lstmb{} and \lstmc{} we used the word vector representation
explained in \cref{sec:word-vectors}. We trained \ac{glove} with a window dimension of $15$,
in $50$ iterations to produce representations in dimension $60$. To
decide those parameters we developed intrinsic tests collecting
quadruples like:
$$
(melanoma,\ cute,\ duttale,\ mammella)
$$
translated:
$$
(melanoma,\ skin,\ ductal,\ breast)
$$
in order to verify if $\vect{x}_{breast}$ is near
$\vect{x}_{skin}-\vect{x}_{melanoma}+\vect{x}_{ductal}$. Then we
proceeded to confront the different parameters as in
\cref{fig:gloveParameter}.

In order to speed up the computation for the models \lstmng{}, \lstmb{}
and \lstmc{} we cut the length of text to 200. Covering completely the
$87\%$ of records.

\lstmng{} is the \ac{ann} in \cref{fig:schemeLstmng},
composed of two layers of $150$ bidirectional \ac{lstm} cells,
followed by an average pooling of the sequences, followed by a
dense \ac{relu} layer, followed by a dense \emph{softmax} layer.
The number of \acp{an} of the last two layers is
equal to the number of classes for each task.
\begin{figure}
  \centering
  \begin{tikzpicture}[node distance = 0.1cm, auto]
    \begin{scope}[start chain, every node/.style={on chain}, node distance = \schemeNodeDistance]
      \nodeInput();
      \nodeEmbedding();
      \node[support] (emb) {};
      \nodeLstm();
      \node[support] (lstmA) {};
      \nodeLstm();
      \node[support] (lstmB) {};
      \nodeAvg();
      \node[support] (avg) {};
      \nodeRelu();
      \node[support] (relu) {};
      \nodeSoftmax();
      \node[dataLabel, joined] {$outDim$};
    \end{scope}
    \node[dataLabel, above=of emb] {$200\times 30$};
    \node[dataLabel, above=of lstmA] {$200\times 300$};
    \node[dataLabel, above=of lstmB] {$200\times 300$};
    \node[dataLabel, above=of avg] {$300$};
    \node[dataLabel, above=of relu] {$outDim$};
  \end{tikzpicture}
  \caption{Scheme for \lstmng{} model.}
  \label{fig:schemeLstmng}
\end{figure}

\lstmc{}, in \cref{fig:schemeLstmc} is composed of a convolutional
filter of size two, followed by a bidirectional \ac{lstm} layer of
$150$ cells, followed by an average pooling of the sequences,
followed by a dense \ac{relu}, followed by a dense \emph{softmax}
layer.
\begin{figure}
  \centering
  \begin{tikzpicture}[node distance = 0.1cm, auto]
    \begin{scope}[start chain, every node/.style={on chain}, node distance = \schemeNodeDistance]
      \nodeInput();
      \nodeGlove();
      \node[support] (glove) {};
      \nodeConv();
      \node[support] (conv) {};
      \nodeLstm();
      \node[support] (lstm) {};
      \nodeAvg();
      \node[support] (avg) {};
      \nodeRelu();
      \node[support] (relu) {};
      \nodeSoftmax();
      \node[dataLabel, joined] {$outDim$};
    \end{scope}
    \node[dataLabel, above=of glove] {$200\times 60$};
    \node[dataLabel, above=of conv] {$199\times 100$};
    \node[dataLabel, above=of lstm] {$199\times 300$};
    \node[dataLabel, above=of avg] {$300$};
    \node[dataLabel, above=of relu] {$outDim$};
  \end{tikzpicture}
  \caption{Scheme for \lstmc{} model.}
  \label{fig:schemeLstmc}
\end{figure}

\lstmb{} in \cref{fig:schemeLstmb} is composed of two bidirectional
\ac{lstm} layer of 
$150$ cells, followed by an average pooling of the sequences,
followed by a dense \ac{relu}, followed by a dense \emph{softmax}
layer. 
\begin{figure}
  \centering
  \begin{tikzpicture}[node distance = 0.1cm, auto]
    \begin{scope}[start chain, every node/.style={on chain}, node distance = \schemeNodeDistance]
      \nodeInput();
      \nodeGlove();
      \node[support] (glove) {};
      \nodeLstm();
      \node[support] (lstmA) {};
      \nodeLstm();
      \node[support] (lstmB) {};
      \nodeAvg();
      \node[support] (avg) {};
      \nodeRelu();
      \node[support] (relu) {};
      \nodeSoftmax();
      \node[dataLabel, joined] {$outDim$};
    \end{scope}
    \node[dataLabel, above=of glove] {$200\times 60$};
    \node[dataLabel, above=of lstmA] {$200\times 300$};
    \node[dataLabel, above=of lstmB] {$200\times 300$};
    \node[dataLabel, above=of avg] {$300$};
    \node[dataLabel, above=of relu] {$outDim$};
  \end{tikzpicture}
  \caption{Scheme for \lstmb{} model.}
  \label{fig:schemeLstmb}
\end{figure}

We trained \lstmng{}, \lstmc{} and \lstmb{} minimizing
the \emph{categorical crossentropy}.

\subsection{Experiments}
\label{sec:experiments}
Machine learning models need a training dataset in order to learn how
to perform predictions. A second dataset — sampled from the same
distribution — is needed to assess the performances of the
classifier. We will use leave-one-out ten-folds cross validation
to take advantage of all the available data. The whole
pathological-record dataset is split in ten equal parts called
folds. To preserve labels distribution, this is performed in a
stratified way (all the folds have the same proportions of
labels). Afterwards, each
model is trained ten times, using one fold at a time as test
dataset and the rests as training. For each metric we summarize the
average and the standard deviation among the runs. Regarding the
curves we calculated the cumulative for each 
one, i.e.\ we concatenate the prediction for all the folds and
calculate the curves on them. 

\begin{table}
  \centering
  %\scriptsize
  \footnotesize
  %\small
  \input{tabs/site.tex}
  \caption{Results for \site{} task.}
  \label{tab:resultsSite}
\end{table}

\begin{table}
  \centering
  %\scriptsize
  \footnotesize
  %\small
  \input{tabs/fullSite.tex}
  \caption{Results for \fullSite{} task.}
  \label{tab:resultsFullSite}
\end{table}

\begin{table}
  \centering
  %\scriptsize
  \footnotesize
  %\small
  \input{tabs/type.tex}
  \caption{Results for \type{} task.}
  \label{tab:resultsType}
\end{table}

\begin{table}
  \centering
  %\scriptsize
  \footnotesize
  %\small
  \input{tabs/behaviour.tex}
  \caption{Results for \behaviour{} task.}
  \label{tab:resultsBehaviour}
\end{table}

The results are resumed in \cref{tab:resultsSite}, \cref{tab:resultsFullSite},
\cref{tab:resultsType}
and \cref{tab:resultsBehaviour}, one table for each task described
in \cref{sec:dataset}, one column for each 
model described in \cref{sec:models}. Rows specify the metrics
described in \cref{sec:metrics}, with also macro and weighted average
for precision, recall and $F_1$ score. Micro averages are not
visualized because equivalent to accuracy. Values are expressed in
percentage, indicating average and standard deviation among folds.
%, furthermore for the model \lstmb{} we added another
%task: \emph{full site stacked}. Such task is to classify the \emph{full site}
%having already the \emph{site} code assigned.

\begin{figure}
  \centering
  \resizebox{0.9\textwidth}{!}{\input{img/plots/pr-curve-sede1-macro.pgf}}
  \caption{Macro-averaged recall-precision curves for \site{} task.}
  \label{fig:curvesSite}
\end{figure}

\begin{figure}
  \centering
  \resizebox{0.9\textwidth}{!}{\input{img/plots/pr-curve-sede12-macro.pgf}}
  \caption{Macro-averaged recall-precision curves for \fullSite{} task.}
  \label{fig:curvesFullSite}
\end{figure}

\begin{figure}
  \centering
  \resizebox{0.9\textwidth}{!}{\input{img/plots/pr-curve-morfo1-macro.pgf}}
  \caption{Macro-averaged recall-precision curves for \type{} task.}
  \label{fig:curvesType}
\end{figure}

\begin{figure}
  \centering
  \resizebox{0.9\textwidth}{!}{\input{img/plots/pr-curve-morfo2-macro.pgf}}
  \caption{Macro-averaged recall-precision curves for \behaviour{} task.}
  \label{fig:curvesBehaviour}
\end{figure}

Macro-averaged recall-precision curves for every method and task are
resumed in \cref{fig:curvesSite}, \cref{fig:curvesFullSite},
\cref{fig:curvesType} and
\cref{fig:curvesBehaviour}. Areas under the curves are indicated in
plot legends.

\section{Discussion}
The aim of this paper was to investigate different machine learning
models for cancer cases classification based on the interpretation
of pathological-reports free text.

Considering \ac{svm} models, the improvement of using
bigrams respect monograms is not remarkable.

The use of deep learning is not necessarily beneficial to the
classification task. In fact \lstmng{}
performs worst compared to \ac{svm} models. Instead, when we take
advantage of the unlabeled data with \ac{glove}, we notice an
improvement.

\lstmb{} performs always better than the other models, except
regarding macro-averaged precision, where \ac{svm} models are better.

Since the cancer registration process is partially based on manual
revision, including also the free text interpretation in pathological
reports, a delay in data production and publication may occur. This
weakens data relevance for the purpose of assessing compliance with
regional updated recommended integrated case pathways, as well as for
public health purposes.

Improving automated methods to generate a list of putative incident
cases and to automatically estimate process indicators is an
opportunity to perform an up-to-date evaluation of cancer-care
quality.

This work demonstrated that the machine learning approaches can be
used to provide an automated support in cancer classification based on
the information contained in free-text pathology reports.

Machine learning techniques overcome the previously mentioned
delay in cancer case definition by cancer registry and allow a
powerful tool for timely indicators computation. The implementation of
this procedure guarantee an automated and validated instrument to
monitor and evaluate diagnostic and therapeutic pathways in the
health care context.

\section{Conclusions}
We analyzed the available data and realized different models in order
to implement an automated classification system. We obtained a very
encouraging result in classifying cancer cases based on the
interpretation of free text pathology reports data flow, suggesting that
machine learning methods can be usefully leveraged in this context.

We also took advantage from the unlabeled data in order to improve
the classification. Ours models have also the added value that can be
utilized to retrieve records adjusting the precision-recall trade-off.

The use of updated administrative data sources combined with powerful
machine learning techniques to automate text classification is in the
interest of a standardized surveillance system development at Regional
and National level.

The availability of timely indicators, routinely automatically
produced, is technically possible and necessary for evaluating the
efficiency of the health care system. The main novelty of the present
project is the application of machine learning techniques, not jet
systematically implemented in other Italian contexts.

Stakeholders and decision makers need timely and updated indicators to
evaluate and plan healthcare activities. This work demonstrated the
power of machine learning techniques in cancer cases classification
based on the most updated administrative data sources (i.e. free text
pathology reports). This provides a useful monitor tool for cancer
patients pathways, allowing to describe population’s general health
state and to establish public health goals.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
