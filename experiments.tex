\chapter{Experiments}
With the experiments we want to show the feasibility of deep learning
methods and, more generally, machine learning methods applied to large
scale histological records. Moreover, we want to compare classical
bag-of-word techniques with recent deep learning methods. We also want
to assess the effects of leveraging large corpora of unlabeled text
that comes from the same distribution, in the context of text
classification. Finally, we want to check if attention-based methods
determine an improvement, especially when used in a hierarchic way
like in
previous works. We also want to show some practical use cases and
evaluate the interpretation of deep learning models.

In \cref{sec:metrics}, we describe some useful metrics that can
be used to assess the 
classifier behavior and also to use the classifiers in different use
cases.

In \cref{ch:icdoFirst}, we organize a comparative study between
\ac{svm} and deep learning techniques using both bag-of-words and word
vectors. We trained the models \svm, \svmb, \lstmng, \lstmc, and
\lstmb in 10-fold cross validation. We calculated 
different metrics for all the models and we summarized the average and
standard deviation 
along the folds. In these
experiments we can appreciate the improvements of using word
vectors. Furthermore, we can notice that by using \ac{svm}, either on
unigrams and bigrams, we already achieved good results.

Related to the motivations in \cref{sec:motivation}, with these
experiments we want to prove Q1. Also we want to answer to Q3 by
comparing ac{lstm} with
\ac{svm} with both \ac{glove} and bag-of-word features.  
With the training of word vectors we also want to answer to Q5.

In \ref{ch:artificial} we want to investigate the potentialities of
the attention based models and the simpler max aggregation. We
designed an artificial experiment where the two different
kinds of aggregation are compared. Moreover, we also used this artificial
dataset to preliminarily investigate the interpretability
potentialities of \maxi{} and \softmaxi{}. With these experiments we
want to show that the attention model is not always better than a
simpler max aggregation.

Regarding to the questions in \cref{sec:motivation}, these
artificial experiments are a preliminary answer to Q4 and Q6 because
we confront attention-based techniques with simpler aggregation
techniques. Also in these experiments we start to study the
interpretability of the models. 

In \cref{ch:icdo}, we changed the setting, instead of doing a 10-fold
cross validation we adopt a temporal split. This decision was made to
reflect a probable practical employment of the classifier, where it is
being trained on the past data and evaluated on future data. In these
experiments we are interested in evaluating the effects of the
attention models, comparing them with a simpler form constituted by
the max aggregation of \maxp{}. We focused on \ac{gru} because
preliminary experiments did not show an improvement of using
\ac{lstm}. With these experiments, we want to show that in this context
the adoption of hierarchical models is not beneficial. Moreover, we
want to evaluate how the interpretable models work respect to the
others.

Regarding the questions in \cref{sec:motivation}, these experiments
answer to Q1 (with different settings respect to the experiments in
\cref{ch:icdoFirst}). We answer to Q2 and Q4 because we apply attention and
hierarchical models to the cancer pathology reports. We also want to
answer to Q6 because we implement interpretable models. 


\section{Bag-of-words, word vectors, \ac{svm} and deep learning}
\label{ch:icdoFirst}
The focus of this section is to asses the improvement of employing
word vectors respect to the use of bag-of-words and to evaluate the
employment of deep learning techniques.

We realized four multiclass classifiers for the
histological exams. Calling $X$ the distribution of texts, $Y^s$
of site, $Y^f$ of full site (site plus subsite), $Y^t$ of type, and
$Y^b$ of behavior:
\begin{description}
  \item[\site{}] estimates $P(Y^s|X)$;
  \item[\fullSite{}] estimates $P(Y^f|X)$;
  \item[\type{}] estimates $P(Y^t|X)$;
  \item[\behaviour{}] estimates $P(Y^b|X)$.
\end{description}

% The different tasks are not fully independent: obviously \fullSite{}
% classification depends on \site{} classification, but also \type{},
% \behaviour{} and \site{} can be interdependent. Many types of tumor are
% associated to a specific site, some types even indicates a
% specific behavior. For instance, \type{} $8253$
% corresponds to the definition of \emph{bronchio-alveolar carcinoma,
%   mucinous}, and it can be only malignant (\behaviour{} $3$) and located in
% bronchus and lungs (\site{} $34$). Thus, some configurations are impossible.

% Every task is a multiclass classification problem because every
% record is assigned to a single couple of \ac{icdo} codes,
% topographical and morphological.

% We considered the third \ac{icdo} version. There are
% $94\,061$ records with \ac{icdo3} codes.
The tasks have a variable number of represented classes, summarized in
\cref{fig:numClasses}.
\begin{table}
  \center
  \caption{Number of classes for different tasks.}
  \label{fig:numClasses}
  \begin{tabular}{|l|c|}
    \hline
    task & classes \\
    \hline
    \site{} & 70 \\
    \fullSite{} & 284 \\
    \type{} & 434 \\
    \behaviour{} & 5 \\
    \hline
  \end{tabular}
\end{table}
Moreover, data is not balanced. As visible in \cref{fig:classDist},
some classes are common, while many are rare.
% In order to collect more than the
% $90\%$ of the 
% records it is sufficient to take the most frequent classes: $17$ over $70$
% for \site{}, $50$ over $284$ for \fullSite{},
% $44$ over $434$ for \type{}, and $2$ over $5$ for \behaviour{}
% classifications.
\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{img/classDist-icdo3-site.pdf}
  \includegraphics[width=0.45\textwidth]{img/classDist-icdo3-fullSite.pdf}
  \includegraphics[width=0.45\textwidth]{img/classDist-icdo3-type.pdf}
  \includegraphics[width=0.45\textwidth]{img/classDist-icdo3-behaviour.pdf}
  \caption{Documents in classes (ordered by
    frequency).}
  \label{fig:classDist}
\end{figure}

The frequency of words in the text
follows the typical Zipf's distribution with few words that cover the
majority of text and a long tail of infrequent words.
% The $85\%$ of
% the $9\,264\,143$ words in text is covered With $500$
% over a total of $35\,216$ distinct words. 


\subsection{Experiments}
\label{sec:experiments}
We used leave-one-out ten-folds cross validation
to take advantage of all the available data. The whole
pathological-record dataset was split in ten equal parts called
folds. To preserve labels distribution, this was performed in a
stratified way (all the folds have the same proportions of
labels). Afterwards, each
model was trained ten times, using one fold at a time as test
dataset and the remaining as training. For each metric we summarized the
average and the standard deviation among the runs. Regarding the
curves we calculated the cumulative for each 
one, i.e.\ we concatenated the prediction for all the folds and
calculated the curves on them. 

\begin{table}
  \centering
  \caption{Results for \site{} task.}
  \label{tab:resultsSite}
  %\scriptsize
  \footnotesize
  %\small
  \input{tabs/site.tex}
\end{table}

\begin{table}
  \centering
  \caption{Results for \fullSite{} task.}
  \label{tab:resultsFullSite}
  %\scriptsize
  \footnotesize
  %\small
  \input{tabs/fullSite.tex}
\end{table}

\begin{table}
  \centering
  \caption{Results for \type{} task.}
  \label{tab:resultsType}
  %\scriptsize
  \footnotesize
  %\small
  \input{tabs/type.tex}
\end{table}

\begin{table}
  \centering
  \caption{Results for \behaviour{} task.}
  \label{tab:resultsBehaviour}
  %\scriptsize
  \footnotesize
  %\small
  \input{tabs/behaviour.tex}
\end{table}

The results are summarized in
\cref{tab:resultsSite,tab:resultsFullSite,tab:resultsType,tab:resultsBehaviour},
one table for each task, one column for each 
model described in \cref{sec:models}. Rows specify the metrics
described in \cref{sec:metrics}, with also macro and weighted average
for precision, recall and $F_1$ score. Micro averages are not
visualized because equivalent to accuracy. Values are expressed in
percentage, indicating average and standard deviation among folds.
%, furthermore for the model \lstmb{} we added another
%task: \emph{full site stacked}. Such task is to classify the \emph{full site}
%having already the \emph{site} code assigned.

\begin{figure}
  \centering
  \resizebox{0.9\textwidth}{!}{\input{img/plots/pr-curve-sede1-macro.pgf}}
  \caption{Macro-averaged recall-precision curves for \site{} task.}
  \label{fig:curvesSite}
\end{figure}

\begin{figure}
  \centering
  \resizebox{0.9\textwidth}{!}{\input{img/plots/pr-curve-sede12-macro.pgf}}
  \caption{Macro-averaged recall-precision curves for \fullSite{} task.}
  \label{fig:curvesFullSite}
\end{figure}

\begin{figure}
  \centering
  \resizebox{0.9\textwidth}{!}{\input{img/plots/pr-curve-morfo1-macro.pgf}}
  \caption{Macro-averaged recall-precision curves for \type{} task.}
  \label{fig:curvesType}
\end{figure}

\begin{figure}
  \centering
  \resizebox{0.9\textwidth}{!}{\input{img/plots/pr-curve-morfo2-macro.pgf}}
  \caption{Macro-averaged recall-precision curves for \behaviour{} task.}
  \label{fig:curvesBehaviour}
\end{figure}

Macro-averaged recall-precision curves for every method and task are
summarized in
\cref{fig:curvesSite,fig:curvesFullSite,fig:curvesType,fig:curvesBehaviour}. Areas
under the curves are indicated in 
plot legends.

One of the aims of these experiments was to investigate different
machine learning 
models for cancer cases classification based on the interpretation
of pathological-reports free text. We can state that
Considering \ac{svm} models, the improvement of using
bigrams respect to monograms is not remarkable.
The use of deep learning is not necessarily beneficial to the
classification task, we already obtained good results using \ac{svm}
models. We can also observe that, when we took 
advantage of the unlabeled data with \ac{glove}, we achieved an
improvement.
\lstmb{} performs always better than the other models, except
regarding macro-averaged precision, where \ac{svm} models are better.

This work demonstrated that the machine learning approaches can be
used to provide an automated support in cancer classification based on
the information contained in free-text pathology reports.

\section{Aggregation and interpretability}
\label{ch:artificial}

Classic \ac{rnn} approaches exhibit some limits related to
memory. We designed an artificial experiment in
order to investigate how \ac{rnn} and \maxp{} address those
problems. The purpose of these experiments is to compare compare plain
\ac{rnn} models with attention-based models. Moreover, we also want to
compare the attention with the max-pooling based models, and start to
explore the potentiality of the interpretable setting. The dataset 
$\mathcal{D}=(\vect{X}\in [0,\dots,9]^{n\times m},\vect{y}\in [0,1]^n)$ is
composed of $n$ sequences of length
$m$ of digits $x_{i,j}\in[0,\dots,9]$. If the $i$-th sequence contains
at least three consecutive digits
$x_{i,j-1},x_{i,j},x_{i,j+1}$ that concatenated represent a prime
number, then the
sample is positive and labeled with $y_i=1$, otherwise is negative and
$y_i=0$.

We realized a series
$\mathcal{D}^{(m)}=(\vect{X}^{(m)},\vect{y}^{(m)})$ of balanced
datasets of increasing complexity. Each $\mathcal{D}^{(m)}$ has $100\ 000$
samples with 
sequence lengths of
$$
m\in[100,200,300,400,500,600,700,800,900,1000].$$
We chose this setting because we wanted to underline the memorizing
capability of \ac{gru}. In fact, the network needs to keep track in
his memory of
all the sequence, and the larger the sequence, the higher the amount of
memory needed.

We trained four models on
all the datasets: a plain \ac{gru}, a
\maxp{}, a \softmax{}, and a \maxi{}, all with the same hidden dimension of $32$. 

\begin{figure}
  \centering
  \includegraphics[width=\floatwidth]{imgMax/accuracy-base.eps}
  \caption{Accuracy of plain \ac{gru} on $\mathcal{D}^{(m)}$ for different dimensions of $m$.}
  \label{fig:testAccBase}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\floatwidth]{imgMax/accuracy-max.eps}
  \caption{Accuracy of \maxi{} on $\mathcal{D}^{(m)}$ for different dimensions of $m$.}
  \label{fig:testAccMax}
\end{figure}

In \cref{fig:testAccBase} and \cref{fig:testAccMax}, we compare
the learning curves of the two model trained on the increasing
difficulty problems. We can observe 
that \maxp{} degrades less than the baseline under the assumption of
having the same dimensionality. The interpretation for this can be
that the max pooling forces locality on the sequence, thus simplifying
the task for the underlying \ac{rnn} that at time $t$ needs to keep
track only of the neighbors of $t$ in the sequence. Thus, \maxp{} can
be used on increasingly long sequences without losing potentiality.

\begin{figure}
  \centering
  \includegraphics[width=\floatwidth]{imgMax/accuracy-int.eps}
  \caption{Accuracy of \maxi{} on $\mathcal{D}^{(m)}$ for different dimensions of $m$.}
  \label{fig:testAccInt}
\end{figure}

\begin{figure}
  \centering
  \footnotesize
  \begin{tabular}{|p{\floatwidth}|}
    \hline
    \input{attentions/test1.tex}\\
    \hline
    \input{attentions/test2.tex}\\
    \hline
    \input{attentions/test3.tex}\\
    \hline
    \input{attentions/test4.tex}\\
    \hline
    \input{attentions/test5.tex}\\
    \hline
    \input{attentions/test6.tex}\\
    \hline
  \end{tabular}
  \caption{Visualization of outputs prior to the max pooling of
    \maxi{} for some 
    samples. Red boxes represent the prime numbers ground
    truth, green highlighting represents the values of $u_t$ in
    \eqref{eq:maxModelF}.}
  \label{fig:testAttention}
\end{figure}

Regarding the interpretable models, we can observe that
the degradation of the interpretable \maxi{} model in
fig. \ref{fig:testAccInt} is worse 
compared to \maxp{} in fig. \ref{fig:testAccMax},
but is still better compared to the base \ac{gru} model in
fig. \ref{fig:testAccBase}. Conversely, the interpretable model can be
used to gain
some insights on the decision process. As visible in
fig. \ref{fig:testAttention}, the model performs the classification
task focusing on 
the part of the sequences where the prime numbers are present. The
reasons why \maxi{} is not scaling as \maxp{} can be found in the fact
that in the interpretable setting we basically moved the aggregation
from before to after the classification part. The max pooling in
\maxi{} does not have the same localizing effect on the underlying
part. Nevertheless, it still has some effect on simplifying the
task.

\begin{figure}
  \centering
  \footnotesize
  \begin{tabular}{|p{\floatwidth}|}
    \hline
    \input{attentions/testS1.tex}\\
    \hline
    \input{attentions/testS2.tex}\\
    \hline
    \input{attentions/testS3.tex}\\
    \hline
  \end{tabular}
  \caption{Visualization of weighted features after softmax in
    \softmaxi{} for some
    positive samples. Red boxes represent the prime numbers ground
    truth, green highlighting represents the values of
    $a_t(\vect{u};\theta^a)u_t$ in
    \eqref{eq:aggregation}.}
  \label{fig:testAttentionSoft}
\end{figure}
We wanted also to compare the difference of the max vs attention
aggregation. In 
\cref{fig:testAttentionSoft} we have empirical evidence that the
attention aggregation is not sufficient to guarantee the model
interpretability (at least in this setting). This can be explained
with the fact that the softmax function does 
not avoid the learning of underlying
distribute representations. 
On the loss calculation, the effects of a
distribution with high variance before the aggregation are the 
same to the ones of a distribution with lower variance. Thus, the \ac{sgd} does
not favor focused representations in $u_t$.

\begin{figure}
  \centering
  \includegraphics[width=\floatwidth]{imgMax/maxBaseDiff.eps}
  \caption{Max reached accuracy of \maxp{}, \softmax{}, \maxi{}, and
    base \ac{gru} models on
    $\mathcal{D}^{(m)}$ for different dimensions of $m$.} 
  \label{fig:testAccDiff}
\end{figure}
In \cref{fig:testAccDiff}, we show the maximum reached accuracy for the
models, summarizing
\cref{fig:testAccBase,fig:testAccMax,fig:testAccInt} and also adding
\softmax{}. From this plot we can evince that \softmax{} degrades
faster than \maxp{}. This can be due to the fact that the attention,
using a softmax on all the underlying representations,
still needs to rely on the entire sequence. Thus, there is not the
strong focusing effect of the max aggregation.


\section{Aggregation, interpretability, hierarchical}
\label{ch:icdo}
In these experiments we further refined the dataset. We removed duplicate
reports and reports labeled with extremely rare (1048
samples that do not
appear in all three of training, validation, and test sets) ICD-O3
codes. In the end we
obtained 
a dataset suitable for supervised learning consisting of $85\,170$
labeled records, over $203$ morphological classes, and $68$
topological classes.

We defined two multi-class classification tasks: (1) main tumor site
prediction ($68$ mutually exclusive classes) and (2) morphology
prediction ($203$ mutually exclusive
classes). Although the two tasks maybe somewhat correlated, we did not
attempt multi-task approaches given the small number of tasks and
large enough size of the dataset.

We decided to arrange our experiments on cancer
data in 
a setting that simulates a predictive task. We sorted the medical
records by insertion date, then we used the most recent $80\%$ of
records as test 
dataset, an equal amount of the remaining most recent records as
validation dataset, and the rest as training dataset. The splitting of
data resulted in $51\,101$ records for training,
$17\,034$ for validation, and $17\,035$ for test datasets.

We used the text in the $1.5$ millions unlabeled records, plus the
text in training datasets to train \ac{glove} word
vectors representations.

We trained the models \maxp{}, \softmax{}, \maxi{}, \maxh{}, and
\softmaxh{} on both prediction tasks. We found the hyperparameters 
configurations doing grid search on the space explained in
\cref{sec:hyperparameters}. 
% \maxi{} have one \ac{gru} layer of dimension $256$
% for \eqref{eq:maxModelRL} and \eqref{eq:maxModelRR}, 1 layer of
% output dimension $68$ with aggregating function \eqref{eq:aggregation}
% for \eqref{eq:maxModelF}, and zero layers for \eqref{eq:maxModelC}. 
% \maxp{} have
% one \ac{gru} layer with
% dimension $128$ for \eqref{eq:maxModelRL} and \eqref{eq:maxModelRR},
% one \ac{mlp} layer of dimension $512$ with aggregating function
% \eqref{eq:aggregation} for \eqref{eq:maxModelF}, and
% one layer of output dimension $68$ for \eqref{eq:maxModelC}.

We trained the models minimizing categorical cross entropy with Adam
\cite{kingma2014adam} using a starting learning rate of $0.001$. The
experiments were performed in \emph{PyTorch} on machines with
\emph{GeForce RTX 2080 Ti} 
GPU using batches of $32$ samples.

% We compared \maxp{} and \maxi{} with the baseline \gru{}  and with
% \bert{} pretrained on the 
% same data where \ac{glove} where trained for the other models, and
% fine-tuned on the training set.


\subsection{Hyperparameters}\label{sec:hyperparameters}
The hyperparameters of \eqref{eq:embed}~-~\eqref{eq:maxModelC}
and \eqref{eq:embedH}~-~\eqref{eq:maxModelCH} control the structure of
the model.

$\xi^e$ is associated with the embedding layer $E$ and in our case
refers to \ac{glove} 
hyperparameters~\cite{pennington_glove:_2014}. With an intrinsic
evaluation, we found that the better configuration was $60$ for the vector
size, $15$ for the window size, and $50$ iterations. $\xi^f$,
$\xi^r$, $\xi'^{f}$, and $\xi'^{r}$ define the number of
\ac{gru} layers ($\xi_{(l)}$) and the number of unit per each layer
($\xi_{(d)}$) respectively for $F$, $R$, $F'$, and $R'$. 
$G$ is a \ac{mlp}, $\xi^h$ controls the number of
layers and their dimension. Regarding $F$, $R$, and $G$, we decided to
have all the stacked layer with 
the same dimension to limit the
hyperparameters space. $\xi^a$ and $\xi'^a$ control the
kind of aggregating function of $A$ and $A'$ respectively and, in case
of \emph{attention}, 
it controls the dimension of the attention layer. Finally, $\xi^c$ controls the
data-dependent output dimension of $g$.

In \maxp{} we used the \emph{max} aggregation
function 
in the plain model of \cref{sec:modelh}. We determined the
hyperparameters evaluating the validation set in the space (with the
better configuration underlined):
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r&\in[\underline{1},2],\\
  \xi_{(d)}^f=\xi_{(d)}^r&\in[2,4,8,16,32,64,\underline{128},256,512],\\
  \xi_{(l)}^h&\in[\underline{1},2,4],\\
  \xi_{(d)}^h&\in[2,4,8,16,32,64,128,256,\underline{512},1024,2048],
\end{align*}
for the \emph{main site} task, and:
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r&\in[\underline{1}],\\
  \xi_{(d)}^f=\xi_{(d)}^r&\in[2,4,8,16,32,64,\underline{128},256,512],\\
  \xi_{(l)}^h&\in[\underline{1},2,4],\\
  \xi_{(d)}^h&\in[2,4,8,16,32,64,\underline{128},256,512,1024,2048],
\end{align*}
for the \emph{morphology} task.

In \softmax{} we used the \emph{attention} aggregation function in the
plain model. The hyperparameters
space was:
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r&\in[\underline{1}],\\
  \xi_{(d)}^f=\xi_{(d)}^r&\in[64,\underline{128},256],\\
  \xi_{(l)}^h&\in[0,\underline{1}],\\
  \xi_{(d)}^h&\in[256,\underline{512},1024],\\
  \xi_{(d)}^a&\in[128,\underline{256},512,1024],
\end{align*}
for the site, and:
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r&\in[\underline{1}],\\
  \xi_{(d)}^f=\xi_{(d)}^r&\in[64,128,\underline{256}],\\
  \xi_{(l)}^h&\in[0,\underline{1}],\\
  \xi_{(d)}^h&\in[64,\underline{128},256],\\
  \xi_{(d)}^a&\in[128,\underline{256},512,1024],
\end{align*}
for the morphology.

In \maxh{} we used the \emph{max} aggregation in the hierarchical
model of \cref{sec:modelh}. The hyperparameters space was:
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r=\xi'^f_{(l)}=\xi'^r_{(l)}&\in[\underline{1}],\\
  \xi_{(d)}^f=\xi_{(d)}^r=\xi'^f_{(d)}=\xi'^r_{(d)}&\in[32,\underline{64},128,256],\\
  \xi_{(l)}^h&\in[0,1,\underline{2},4],\\
  \xi_{(d)}^h&\in[256,512,\underline{1024},2048],\\
\end{align*}
for the site, and:
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r=\xi'^f_{(l)}=\xi'^r_{(l)}&\in[\underline{1}],\\
  \xi_{(d)}^f=\xi_{(d)}^r=\xi'^f_{(d)}=\xi'^r_{(d)}&\in[32,\underline{64},128,256],\\
  \xi_{(l)}^h&\in[0,\underline{1},2,4],\\
  \xi_{(d)}^h&\in[256,512,\underline{1024},2048],\\
\end{align*}
for the morphology.

In \softmaxh{} we used the \emph{attention} aggregation in the
hierarchical model. The hyperparameters space was:
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r=\xi'^f_{(l)}=\xi'^r_{(l)}&\in[\underline{1}],\\
  \xi_{(d)}^f=\xi_{(d)}^r=\xi'^f_{(d)}=\xi'^r_{(d)}&\in[32,64,\underline{128},256],\\
  \xi_{(l)}^h&\in[0,\underline{1},2,4],\\
  \xi_{(d)}^h&\in[256,512,\underline{1024},2048],\\
  \xi_{(d)}^a=\xi'^a_{(d)}&\in[64,\underline{128},256,512],
\end{align*}
for the site, and:
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r=\xi'^f_{(l)}=\xi'^r_{(l)}&\in[\underline{1}],\\
  \xi_{(d)}^f=\xi_{(d)}^r=\xi'^f_{(d)}=\xi'^r_{(d)}&\in[32,\underline{64},128,256],\\
  \xi_{(l)}^h&\in[0,\underline{1},2,4],\\
  \xi_{(d)}^h&\in[256,512,\underline{1024},2048],\\
  \xi_{(d)}^a=\xi'^a_{(d)}&\in[64,\underline{128},256,512],
\end{align*}
for the morphology.

In \maxi{} we used the \emph{max} aggregation in the plain
model. Also we set the model to be interpretable. The hyperparameters
space was: 
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r&\in[1,\underline{2},4],\\
  \xi_{(d)}^f=\xi_{(d)}^r&\in[2,4,8,16,32,64,\underline{128},256,512],\\
  \xi_{(l)}^h&\in[\underline{1},2,4],\\
  \xi_{(d)}^h&\in[2,4,8,16,32,64,128,256,512,1024,2048],
\end{align*}
for the site, and:
\begin{align*}
  \xi_{(l)}^f=\xi_{(l)}^r&\in[1,\underline{2},4],\\
  \xi_{(d)}^f=\xi_{(d)}^r&\in[64,128,\underline{256},512],\\
  \xi_{(l)}^h&\in[\underline{1}],\\
  \xi_{(d)}^h&\in[],
\end{align*}
for the morphology. Note that, in this setting, the dimension of the
last layer of $G$ must be equal to the output dimension of the model
(and the softmax is applied directly after the aggregation $A$,
without any layer). Thus, $\xi_{(d)}^h$ refers only to the
layers before the last one, if they exist.

Regarding \gru{}, we searched in a space of $[1,2,4]$ number of layers of
dimension in $[128,256,512,1024]$. We found that the best
configuration was using $2$ layers of dimension $256$.



% The hyperparameters $\xi=\xi^l\cup\xi^r\cup\xi^h\cup\xi^c$ define the
% structure of the model. Regarding $\xi^l=\xi^r$ they define the type
% of \ac{rnn} that in our experiments can be \ac{lstm} or \ac{gru}, the
% number of stacked \ac{rnn} layers and the dimension of each
% layer. $\xi^h$ defines the number of layers in the first
% \ac{mlp} and their
% dimensions, moreover it defines the type of aggregating function $f$
% that in our experiments can be one of
% \begin{align}
%   f(\vect{a},\vect{b}) &= \left[\max(a_1,b_1),\dots,\max(a_l,b_l)\right];\\
%   f(\vect{a},\vect{b}) &= \left[\frac{a_1+b_1}{2},\dots,\frac{a_l+b_l}{2}\right];\\
%   f(\vect{a},\vect{b}) &= \left[a_1,\dots,a_l,b_1,\dots,b_l\right].\label{eq:aggregation}
% \end{align}
% $\xi^c$ defines the number of layers and their dimensions of the
% final classifier. The number of layers defined in $\xi^h$ can be
% equal to $0$. In such case, $\vect{h}_{i,j}$ is calculated:
% \begin{equation*}
%   \vect{h}_{i,j} = f(\vect{h}^l_{i,j},\vect{h}^r_{i,j}).
% \end{equation*}
% Also the number of layers defined in $\xi^c$ can be equal to $0$. In
% such case $\vect{\hat{y}}_i$ is calculated:
% \begin{equation*}
%   \vect{\hat y}_i = \max_j(\vect{h}_{i,j}).
% \end{equation*}


\subsection{Results}

\begin{table}
  \centering
  \caption{Results on cancer data}
  \label{tab:results}
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    &Acc.&Acc. T3&Acc. T5&MAP&K\\
    \hline
    \hline
    \textbf{Site}&&&&&\\
    \gru{}&0.8977&0.9636&0.9764&0.9331&0.8848\\
    \bert{}&0.8980&0.9623&0.9768&0.9330&0.8852\\
    \maxi{}&0.8792&0.9533&0.9610&0.9190&0.8637\\
    \maxh{}&0.8980&0.9611&0.9773&0.9329&0.8851\\
    \softmaxh{}&0.8983&0.9617&0.9760&0.9329&0.8855\\
    \softmax{}&0.9008&0.9607&0.9749&0.9341&0.8883\\
    \maxp{}&\textbf{0.9024}&\textbf{0.9658}&\textbf{0.9797}&\textbf{0.9369}&\textbf{0.8901}\\
    \hline
    \hline
    \textbf{Morpho.}&&&&&\\
    \gru{}&0.8266&0.9402&0.9602&0.8881&0.8064\\
    \bert{}&0.8367&0.9267&0.9439&0.8870&0.8178\\
    \maxi{}&0.7317&0.9012&0.9305&0.8169&0.6964\\
    \maxh{}&0.8313&0.9382&0.9582&0.8894&0.8117\\
    \softmaxh{}&0.8318&0.9388&0.9566&0.8894&0.8119\\
    \softmax{}&\textbf{0.8424}&0.9445&0.9632&\textbf{0.8973}&\textbf{0.8240}\\
    \maxp{}&0.8394&\textbf{0.9452}&\textbf{0.9634}&0.8962&0.8207\\
    \hline
  \end{tabular}
\end{table}
In \cref{tab:results} we summarized the results of the models on the test
dataset. We report accuracy, \ac{map} and Cohen's kappa score (K).

\begin{table}
  \centering
  \ttfamily
  \scriptsize
  \caption{Visualization of interpretable outputs.}
  \label{tab:multiAttention1}
  \begin{tabular}{|c|c|c|}
    \hline
    $y_i$&\textrm{Relevant} $\vect{h}_{i,j}$&$x_{i,j}$\textrm{, relevant} $\vect{h}_{i,j}$\\
    \hline
    \input{attentions/multiB3.tex}
    \hline
    \input{attentions/multiB2.tex}
    \hline
    %\input{attentions/multiB3.tex}
    %\hline
    \input{attentions/multiB4.tex}
    \hline
  \end{tabular}
\end{table}
From the results we observe that the use of hierarchical models and
recent architectures like \ac{bert} is not beneficial in this
context. Moreover, we can see that attention models are equivalent to a
simpler max pooling.

The interpretable model is not as powerful as \maxp{}, and in this task
not even as the baseline, but it can be used as a
classification support and to 
gain insight in the classification process. In
\cref{tab:multiAttention1}, we show three different samples where we
underline with different colors --- only for the indicated relevant
codes --- the values of $\vect{h}_{i,j}$ in \eqref{eq:maxModelF}. We
consider a code relevant if the corresponding value in the
68-dimension vector $\vect{h}_{i,j}$ is greater than $0.1$. In the
first sample, that was correctly classified, all the terms related to
prostate gland cancer are strongly underlined. Apart from
\emph{prostatico} and \emph{prostata} that are Italian terms for
\emph{prostatic} and \emph{prostate}, the main underlined terms are
\emph{PSA} (Prostate-Specific Antigene) and \emph{Gleason} score that
are two common exams in prostate cancer cases
\cite{brimo2013prostate}.

The second sample is a more difficult
document, it is roughly translated in english as:\\
%\smallskip\noindent
\begin{small}
  \ttfamily
  \begin{tabular}{l}
    ISOLATED FRAGMENTS ATTRIBUTABLES\\
    TO HIGH DEGREE\\
    INTESTINAL TUBULAR ADENOMA.\\
    FRAGMENTS (NR. 2) OF PEDUNCULATED\\
    POLYPUS AT 20 CM FROM\\
    THE ANAL ORIFICE. (PERFORMED\\
    HEMATOXYLIN-EOSIN COLORING).
\end{tabular}
\end{small}\\
For this sample, the model propose the three classification codes \emph{18},
\emph{20}, and \emph{21} (with value $1$ for both \emph{18} and
\emph{20}, and little less for \emph{21}). It suggests that the terms
\emph{intestinal tubular adenoma} and \emph{pedunculated polypus} are
related to colon, \emph{polypus} can be related also to rectum, and
\emph{anal orifice} is related to rectum and anus. Note that this
record was labeled from the \ac{rtt} with the code for rectum, while
the medical report 
explicitly mentions that the fragments have been extracted at 20 cm
from the anal orifice (the human rectum is long approximately 12 cm
and the anal canal 3-5 cm \cite{greene2006ajcc}). This record is an
example of the complexity of the dataset. The mislabeling is not
necessarily a human classification error, \ac{rtt} have access to more
information respect to the one contained in our dataset. The fact that
this example refers in particular to an operation to the colon does not
exclude that it was related to a rectum tumor.

The third sample is an even more complex record, in english it is
translated as:\\
\begin{small}
  \ttfamily
  \begin{tabular}{l}
    LEFT PLEURAL EFFUSION OF\\
    UNKNOWN ORIGIN AND LUNG\\
    THICKENING OF UNKNOWN ORIGIN,\\
    NODULES OF THE ABDOMINAL WALL.\\
    CANCEROUS INFILTRATION OF THE\\
    CONNECTIVE-ADIPOSE STROMA.\\
    IMMUNOHISTOCHEMICAL: CK7 +,\\
    CK20 -, TTF-1 -, PROTEIN\\
    S-100 -. 2 CM LESION,\\
    0 X 1,3 X 0,7. 1-2)\\
    SERIAL SECTIONS.
\end{tabular}
\end{small}\\
The model classifies the record mainly with codes \emph{34} and
\emph{80}, and less with \emph{56} and \emph{67}. It underlines with
the lung code the terms
\emph{plurial effusion} and \emph{lung thickening}, but interestingly
it also underlines the immunohistochemical results. The
positive \emph{CK7}, negative \emph{CK20} pattern represents a common
diagnosis 
of lung origin for metastatic adenocarcinoma
\cite{kummar2002cytokeratin}. Also, immunohistochemistry is a common
approach in the diagnosis of tumors of uncertain origin
\cite{duraiyan2012applications}. This can be the reason for the
underlying with code \emph{80} of the immunoistochemical part.
It is interesting to note also that \emph{pleuric} is
suggested to be related to ovary cancer, in fact the pleural cavity
constitutes the most frequent site for extra abdominal metastasis in
ovarian carcinoma \cite{porcel2012pleural}.

These experiments with interpretable models serve the purpose of
illustrating that these models can be useful even if they perform
poorly in the 
classification. In a practical context, it is
possible to combine the more powerful \maxp{} with the interpretable
\maxi{}. A software that helps humans in the classification process
can use \maxp{} to suggest the most-probable class and \maxi{} to
highlight the most relevant terms.

\begin{figure}
  \centering
  \includegraphics[width=\floatwidth]{img/plotSintex.eps}
  \caption{Training of a plain \ac{gru} model on a dataset created
    using \maxi{} and \softmaxi{} to keep the first $k$ words.}
  \label{fig:sintex}
\end{figure}
To quantify the effectiveness of the interpretability, we designed an
experiment where a dataset is created taking for each document the
first $k$ words selected by  
ordering the results of the aggregator $u_t$ in case of \maxi{}, and
$a_t(\vect{u};\theta^a)u_t$ in case of \softmaxi{}. In
\cref{fig:sintex}, 
we plot the accuracy obtained training a plain \ac{gru} model on the
cleaned datasets, for increasing values of $k$. Surprisingly,
even with few words the document is classified practically with
the same results as \gru{}. This can mean both that the
interpretation is working well distilling the document with its most
relevant terms, and that the information contained in our medical
texts is concentrated in few terms. The latter can also be the reason
why in \cref{tab:resultsSite,tab:resultsType} we do not observe a big
improvement in using deep learning methods respect to \acp{svm}.




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
