\chapter{Introduction}
\label{ch:introduction}

\section{Machine Learning}

\section{Neural Networks}
In our work we used a specific kind of \ac{rnn}: \ac{lstm}.
\acp{rnn} are a class of \acp{ann} where the connections are not only
sequential from one layer to the subsequent, but instead they form
loops. 

\subsection{\acf{ann}}
\begin{figure}
  \centering
  \begin{tikzpicture}[x=1.5cm, y=1.5cm]
    \node [] (input-1) at (0,0.5) {$x_1$};
    \node [] (input-2) at (0,0) {$x_2$};
    \node [] (input-3) at (0,-0.5) {$x_3$};
    \node [] (input-missing) at (0,-0.9) {$\vdots$};
    \node [] (input-n) at (0,-1.4) {$x_n$};

    \node [every neuron] (neuron) at (2,-0.5) {$\Sigma$};
    \node [bias] (bias) at (2,-1.3) {$b$};

    \node [activation] (act) at (3,-0.5) {$f$};
    \node [] (output) at (4,-0.5) {$y$};
    
    \foreach \i in {1,...,3,n}
    \draw [arrow] (input-\i) -- (neuron)
    node [above=-0.05, pos=0.3, sloped] {$w_\i$};

    \draw [arrow] (bias) -- (neuron);

    \draw [arrow] (neuron) -- (act);
    \draw [arrow] (act) -- (output);
  \end{tikzpicture}
  \caption{Artificial neuron.}
  \label{fig:neuron}
\end{figure}
An \ac{ann} is a model that performs elaboration in a way that
mimics the brain functioning. The base unit is the \ac{an}, also called
perceptron, of
\cref{fig:neuron}. It performs the weighted sum of the inputs
$x_1,\dots,x_n$, shifted by a bias $b$, followed by an activation
function $f$. If we add a dummy input $x_0=1$ and rename the bias
$b=w_0$, we can express the computation of the \ac{an} as in
\cref{eq:anComp}:
\begin{equation}\label{eq:anComp}
  y = f(\sum_{i=0}^n w_i x_i).
\end{equation}

The activation function $f$ can be of different types, the most common are:
\begin{itemize}
\item Softmax;
\item ReLU;
\item TanH;
\item Sigmoid;
\item Linear;
\end{itemize}

\begin{figure}
  \centering
  \begin{tikzpicture}[x=1.5cm, y=1.5cm]
    \foreach \m/\l [count=\y] in {1,2,3,missing,4}
    \node [every neuron/.try, neuron \m/.try] (input-\m) at (0,2.5-\y) {};

    \foreach \m [count=\y] in {1,missing,2}
    \node [every neuron/.try, neuron \m/.try ] (hidden-\m) at (2,2-\y*1.25) {};

    \foreach \m [count=\y] in {1,missing,2}
    \node [every neuron/.try, neuron \m/.try ] (output-\m) at (4,1.5-\y) {};

    \foreach \l [count=\i] in {1,2,3,n}
    \node[] (x-\i) at ($(input-\i)-(1,0)$) {$x_\l$};

    \foreach \l [count=\i] in {1,2,3,n}
    \draw [arrow] (x-\i) -- (input-\i);
    %\draw [arrowInverse] (input-\i) -- ++(-1,0)
    %node [above, midway] {$I_\l$};

    %\foreach \l [count=\i] in {1,n}
    %\node [above] at (hidden-\i.north) {$H_\l$};

    \foreach \l [count=\i] in {1,m}
    \node[] (y-\i) at ($(output-\i)+(1,0)$) {$y_\l$};
    
    \foreach \l [count=\i] in {1,n}
    \draw [arrow] (output-\i) -- (y-\i);
    %\draw [arrow] (output-\i) -- ++(1,0)
    %node [above, midway] {$O_\l$};

    \foreach \i in {1,...,4}
    \foreach \j in {1,...,2}
    \draw [arrow] (input-\i) -- (hidden-\j);

    \foreach \i in {1,...,2}
    \foreach \j in {1,...,2}
    \draw [arrow] (hidden-\i) -- (output-\j);

    \foreach \l [count=\x from 0] in {Input, Hidden, Ouput}
    \node [align=center, above] at (\x*2,2) {\l \\ layer};

  \end{tikzpicture}
  \caption{\acf{mlp} with one hidden layer.}
  \label{fig:ann}
\end{figure}
\acp{an} are organized in network structures. The basic layout of
an  \ac{ann} is the \acf{mlp} structured in layers like in
\cref{fig:ann}. Each \ac{an} of each layer is connected to all the
outputs of the previous layer. The first layer is connected to the
inputs of the \ac{ann} and the output of the last layer is also the
output of the network. The execution of the \ac{mlp} is feed forward:
\begin{enumerate}
\item the input values $x_{0,1},\dots x_{0,n}$ are presented to the
  network and it is the input of the first layer;
\item  the computation is 
  carried one layer at a time, where each neuron $i$ of the layer $l$
  calculates the value $y_{l,i}$ of the intermediate output
  $y_{l,1},\dots,y_{l,m}$;
\item the intermediate output $y_{l,1},\dots,y_{l,m}$ of the layer $l$
  becomes the 
  input $x_{l+1,1},\dots,x_{l+1,m}$ of the subsequent layer $l+1$,
  unless $l$ is the last layer - in that case the output of $l$ is the
  output $y_1,\dots,y_m$ of the \ac{mlp}.
\end{enumerate}

The weights of the \acp{an} are initialized to random values and, in order
to have meaningful outputs, the \ac{ann} needs to be trained. In a
supervised learning framework the dataset is composed of the matrices
$\matr{X}$ ($N\times n$) of the $N$ inputs $x_{i,j}$, and $\matr{Y}$
($N\times m$) of 
the corresponding outputs $y_{i,j}$. The
training process is called \emph{backpropagation} and it is organized in a
succession of phases. For each phase $p$ there are two steps:
\begin{description}
\item[execution] where an input $x_{p,1},\dots x_{p,n}$ is given to
  the network and an output $\hat{y}_{p,1},\dots,\hat{y}_{p,m}$ is calculated;
\item[weight update] where is calculated the error between
  $\hat{y}_{p,1},\dots,\hat{y}_{p,m}$ and the correct output
  $y_{p,1},\dots,y_{p,m}$, this error is back propagated through all
  the layers and a correction $\Delta w_i$ is calculated for each weight $w_i$ of
  the network, in
  order to minimize the error surface in the space of the weights.
\end{description}
In detail, to calculate the weights $\vect{w}^{(p+1)}$ for the next
phase $p+1$, it is 
sufficient to determine the gradient of 
the error surface in the current point $\vect{w}^{(t)}$ in order to
apply an optimization method like \ac{sgd}.

\subsection{\acf{rnn}}
\acp{rnn} are specialized versions of \ac{ann} for sequences. They
exhibit an
internal state $\vect{h}$ that changes during the training and that
recursively depends on the state of the previous phase. Precisely we
have \cref{eq:rnnState}:
\begin{equation}\label{eq:rnnState}
  \vect{h}^{(t)} = f(\vect{h}^{(t-1)}, \vect{x}^{(t)}; \vect{\theta}),
\end{equation}
where $\vect{h}$ is the state vector, $\vect{x}$ is the input vector
and $\vect{\theta}$ are the hyperparameters of the state-function
$f$. The index $t$ indicates 
the iteration number, and can be interpreted as a discrete time or
more in general as the progressive number of the sequence that is
presented as
input.

\begin{figure}
  \centering
  % \subfigure[]{
  \subfloat[\label{fig:rnn1}]{
    \begin{tikzpicture}[x=1.5cm, y=1.5cm]
      \node [] (input) at (0,0) {$\vect{x}$};

      \node [layer] (state) at (0,1) {$\vect{h}$};
      \node [delay] (delay) at (1,1) {};

      \node [] (output) at (0,2) {$\vect{y}$};
      
      \draw [arrow] (input) -- (state);
      \draw [arrow] (state) -- (output);
      \draw (state) edge[arrow, bend left=60] (delay.north);
      \draw (delay.south) edge[arrow, bend left=60] (state);
    \end{tikzpicture}
  }\hfill
  % \subfigure[]{
  \subfloat[\label{fig:rnn2}]{
    \begin{tikzpicture}[x=1.5cm, y=1.5cm]
      \foreach \l [count=\i] in {t-1,t,t+1}{
        \node [] (input-\i) at (\i*1.2,0) {$\vect{x}^{(\l)}$};
        \node [layer] (state-\i) at (\i*1.2,1) {$\vect{h}^{(\l)}$};
        \node [] (output-\i) at (\i*1.2,2) {$\vect{y}^{(\l)}$};

        \draw [arrow] (input-\i) -- (state-\i);
        \draw [arrow] (state-\i) -- (output-\i);
      }
      \node [layer, dashed] (state-l) at (0,1) {$\vect{h}^{(t-2)}$};
      \node [layer, dashed] (state-r) at (4*1.2,1) {$\vect{h}^{(t+2)}$};

      \draw [arrow] (state-l) -- (state-1);
      \draw [arrow] (state-1) -- (state-2);
      \draw [arrow] (state-2) -- (state-3);
      \draw [arrow] (state-3) -- (state-r);
    \end{tikzpicture}
  }
  \caption{\acf{rnn}, folded (a) and unfolded (b) models.}
  \label{fig:rnn}
\end{figure}
In order to express a compact visualisation of \acp{rnn} it is
possible to use the computational graph in \cref{fig:rnn1} where the
black box is a 
delay of one iteration. An extract of the unfolding of the computation
graph is 
shown in \cref{fig:rnn2}. 

\begin{figure}
  \centering
  \begin{tikzpicture}[x=1.5cm, y=1.5cm]
    \foreach \l [count=\i] in {t,t+1,missing,\tau}{
      \ifthenelse{\equal{\l}{missing}}{
        \node [vmissing] (state-\i) at (\i*1.2,1) {};
        \node [hmissing] (state-\i) at (\i*1.2,0) {};
      }{
        \node [] (input-\i) at (\i*1.2,0) {$\vect{x}^{(\l)}$};
        \node [layer] (state-\i) at (\i*1.2,1) {$\vect{h}^{(\l)}$};
        \draw [arrow] (input-\i) -- (state-\i);
        \ifthenelse{\equal{\l}{\tau}}{
          \node [] (output-\i) at (\i*1.2,2) {$\vect{y}^{(\l)}$};
          \draw [arrow] (state-\i) -- (output-\i);
        }
      }
    }

    \node [layer, dashed] (state-l) at (0,1) {$\vect{h}^{(t-1)}$};
    \node [layer, dashed] (state-r) at (5*1.2,1) {$\vect{h}^{(\tau+1)}$};

    \draw [arrow] (state-l) -- (state-1);
    \draw [arrow] (state-1) -- (state-2);
    \draw [arrow,dashed] (state-2) -- ++(0.8,0);
    \draw [arrowInverse,dashed] (state-4) -- ++(-0.8,0);
    \draw [arrow] (state-4) -- (state-r);
  \end{tikzpicture}
  \caption{\ac{rnn} with single output after a sequence of inputs.}
  \label{fig:rnnSO}
\end{figure}
The model in \cref{fig:rnn} provides an output $\vect{y}^{(t)}$ for every
input $\vect{x}^{(t)}$. An alternative is the model of
\cref{fig:rnnSO} where an output $\vect{y}^{(\tau)}$ is provided only
after a sequence $\vect{x}^{(t)},\dots,\vect{x}^{(\tau)}$ of inputs.

In order to train a \ac{rnn}, it is sufficient to apply the
backpropagation to the entire unfolded model.

\subsection{\acf{lstm}}
The major drawback of \acp{rnn} is the \emph{vanishing
  gradient} problem during the backpropagation. The gradient
for long-term associations, propagated through many stages, tends to
become zero. A possible solution for this problem is \ac{lstm} \cite{hochreiter_1997_lstm}.

\begin{figure}
  \centering
  % \subfigure[]{
  \subfloat[]{
    \begin{tikzpicture}[x=1.5cm, y=1.5cm]
      \node at (1,-0.5) {};

      \node[delay] (delay1) at (1.6,0.8) {};
      \coordinate (input1) at (2.5,0.5);
      \coordinate (input2) at (3.5,0.5);
      \node[] (input01) at (2.5,0) {$in_1$};
      \node[] (input02) at (3.5,0) {$in_m$};
      \node[] at (3,0.2) {$\cdots$};
      \node[every neuron, label={[xshift=-2mm]input}] (inputN) at (1,2) {};
      \node[every neuron, label={[xshift=2mm, align=left, font=\tiny] input\\gate}] (inputGate) at (2,2) {};
      \node[every neuron, label={[xshift=3mm, align=left, font=\tiny] forget\\gate}] (forgetGate) at (3,2) {};
      \node[every neuron, label={[xshift=3mm, align=left, font=\tiny] output\\gate}] (outputGate) at (4,2) {};
      \node[operation] (inputTimes) at (1.5, 3) {$\times$};
      \node[operation, label={[xshift=-3mm]state}] (state) at (2, 4) {$+$};
      \node[delay] (delay2) at (2.7,3.7) {};
      \node[operation] (forgetTimes) at (2.5, 3) {$\times$};
      \node[operation] (outputTimes) at (3, 5) {$\times$};
      \coordinate (output1) at (3,5.5);
      \node (output2) at (3,6) {$out_i$};
      \node at (0.7,5.3) {$cell_i$};

      \fill[black] (input1) circle (1mm);
      \fill[black] (input2) circle (1mm);
      \fill[black] (output1) circle (1mm);
      
      \foreach \n in {input1, input2}{
        \foreach \m in {inputN, inputGate, forgetGate, outputGate}{
          \draw[arrow] (\n) -- (\m);
        }
      }
      \foreach \m in {inputGate, forgetGate, outputGate}{
        \draw[arrow] (delay1) -- (\m);
      }

      \draw[arrow] (inputN) -- (inputTimes);
      \draw[arrow] (inputGate) -- (inputTimes);
      \draw[arrow] (forgetGate) -- (forgetTimes);
      \draw[arrow] (inputTimes) -- (state);
      \draw[arrow] (forgetTimes) -- (state);
      \draw [arrow] (state) ..  controls  (0.15,4) and (0.15,1) ..  (delay1);
      \draw[arrow] (state) -- (delay2);
      \draw[arrow] (delay2) -- (forgetTimes);
      \draw[arrow] (state) -- (outputTimes);
      \draw[arrow] (outputGate) -- (outputTimes);
      \draw[line] (outputTimes) -- (output1);
      \draw[line] (output1) -- (output2);
      \draw[line] (input01) -- (input1);
      \draw[line] (input02) -- (input2);

      \path[border] (0.4,0.5) -- (4.5,0.5) -- (4.5,5.5) -- (0.4,5.5) -- (0.4,0.5); 
      

    \end{tikzpicture}
    \label{fig:lstm1}
  }\hfill
  % \subfigure[]{
  \subfloat[]{
    \begin{tikzpicture}[x=0.8cm, y=0.8cm]
      \node at (1,-2.5) {};

      % \draw[step=1.0,black,thin] (0,3) grid (4,4);
      \draw[step=1.0,black,thin] (0,3) grid (2,4);
      \draw[step=1.0,black,thin] (3,3) grid (4,4);
      \coordinate (input1) at (0.5,3);
      \coordinate (input2) at (1.5,3);
      \coordinate (input3) at (3.5,3);
      \coordinate (inputM1) at (0.5,2.5);
      \coordinate (inputM2) at (1.5,2.5);
      \coordinate (inputM3) at (3.5,2.5);
      \coordinate (output1) at (0.5,4);
      \coordinate (output2) at (1.5,4);
      \coordinate (output3) at (3.5,4);

      \coordinate (outputM) at (2,6);
      \coordinate (outputTM) at (1,6);
      
      \node at (0.5, 3.5) {$cell_1$};
      \node at (1.5, 3.5) {$cell_2$};
      \node at (2.5, 3.5) {$\cdots$};
      \node at (3.5, 3.5) {$cell_n$};
      \coordinate (pass) at (4.5, 3.5);
      \node (inputT) at (1,0) {$\vect{x}$};
      \coordinate (inputTM) at (1,1);
      \node (outputT) at (1,7) {$\vect{y}$};

      \node[delay] (delay) at (4,1) {};

      \foreach \c in {input1, input2, input3, output1, output2, output3}{
        \fill[black] (\c) circle (1mm);
      }

      \foreach \c in {inputM1, inputM2, inputM3}{
        \draw [vectorLine] (delay) ..  controls
        ($0.5*(delay)+0.5*(\c)$) and ($(\c)-(0,0.5)$) ..  (\c);
        \draw [vectorLine] (inputTM) ..  controls
        ($0.5*(inputTM)+0.5*(\c)$) and ($(\c)-(0,0.5)$) ..  (\c);
      }

      \foreach \c in {1, 2, 3}{
        \draw[vectorArrow] (inputM\c) -- ($(input\c)-(0,0.1)$);
      }

      \foreach \c in {output1, output2, output3}{
        \draw [line] (\c) ..  controls  ($(\c)+(0,0.5)$) and
        ($(outputM)-(0,0.5)$) ..  (outputM);
        \draw [line] (\c) ..  controls  ($(\c)+(0,0.5)$) and
        ($(outputTM)-(0,0.5)$) ..  (outputTM);
      }

      %\draw [vectorArrow] (outputM) ..  controls  ($(outputM)+(1,2)$) and ($(delay)+(1,0)$) ..  (delay);
      \draw [vectorArrow]
      (outputM) ..
      controls  ($(outputM)+(1,2)$) and ($(pass)+(0,1)$) ..
      (pass) ..
      controls  ($(pass)-(0,1)$) and ($(delay)+(1,0)$) ..
      (delay);
      \draw[vectorLine] (inputT) -- (inputTM);
      \draw[vectorArrow] (outputTM) -- (outputT);
    \end{tikzpicture}
    \label{fig:lstm2}
  }
  \caption{\ac{lstm} model: detail of memory cell (a), and general
    scheme (b). The black box is a delay of one iteration.}
  \label{fig:lstm}
\end{figure}
The \ac{lstm} model is structured as in \cref{fig:lstm}. It is
equivalent to a
generic \ac{rnn} where the hidden state $\vect{h}$ is a
layer of \emph{memory cells}.

In detail a single
memory cell (\cref{fig:lstm1}) has four \acf{an}. One is labelled \emph{input}
and processes the cell's 
inputs into an internal state. The other three \ac{an} are labelled as
\emph{gates} and process the cell's inputs together with the previous-phase
state in order to decide:
\begin{itemize}
\item how much of the current input must be learned
  (\emph{input gate});
\item how much of the previous-phase state must be forgotten
  (\emph{forget gate});
\item how much of the state constitutes the output (\emph{output gate}).
\end{itemize}

The memory-cells layer (\cref{fig:lstm2}) is composed of a number of
cells equal to the dimension of the output. Each cell
calculates one dimension of $\vect{y}$. The input $\vect{x}$ is copied
for every cell and, together with the previous-phase
output,
constitutes the input $in_1,\dots,in_m$ of the single cells.

\section{metrics}
We used different metrics in order to evaluate the models.
All the metrics are defined between $0$ and $1$ or between $-1$ and $1$,
higher is the value, better is the assessment.

\subsection{Accuracy}
is defined
as the ratio between the correct-classified and all documents. If $\vect{y}$
is the ground truth and $\vect{\hat y}$ is the predicted
classification vectors for $n$ samples, then the accuracy is defined
as:
\begin{equation*}
  accuracy\left(\vect{y}, \vect{\hat y}\right) \equiv
  \frac{1}{n}\sum_{i=1}^{n} 1\left(\hat y_i = y_i\right),
\end{equation*}
Where
\begin{equation*}
  1(a = b)\equiv
  \begin{cases}
    1 & \text{if }a = b,\\
    0 & \text{otherwise}.
  \end{cases}
\end{equation*}

In an
unbalanced dataset, like the one of this work, it is a biased score -
a model that predicts well only the most frequent classes, and ignore
the rest, achieve a good accuracy. To resolve this we considered also
other metrics.

\subsection{Cohen's kappa} score is usually used to asses
the agreement of two annotators \cite{cohen_coefficient_1960}. It
measures the difference between the observed agreement and the
agreement that can happen by choosing randomly the class. It can then
be used to mitigate the bias caused by the unbalanced dataset. Cohen's
kappa is defined as:
\begin{equation*}
  \kappa(\vect{y}, \vect{\hat y})\equiv \frac{p_o(\vect{y}, \vect{\hat y}) -p_e(\vect{y}, \vect{\hat y})}{1-p_e(\vect{y}, \vect{\hat y})} = 1-\frac{1-p_o(\vect{y}, \vect{\hat y})}{1-p_e(\vect{y}, \vect{\hat y})},
\end{equation*}
where $p_o$ is the observed agreement that is equal to the accuracy
and $p_e$ represents the probability of agreement by chance. For $n$
samples and $k$ classes it is
defined by:
\begin{equation*}
  p_e(\vect{y}, \vect{\hat y}) = \frac{1}{n^2}\sum_{i=1}^{k} \mu_{i}(\vect{y})\cdot\nu_{i}(\vect{\hat y}),
\end{equation*}
where $\mu_{i}$ and $\nu_{i}$ are the number of samples classified as
$i$ for the first and second classifier. They are defined as:
\begin{eqnarray*}
  \mu_i(\vect{y}) &=& \sum_{j=1}^{n}1(y_j = i)\\
  \nu_i(\vect{\hat y}) &=& \sum_{j=1}^{n}1(\hat y_j = i)
\end{eqnarray*}

\subsection{\acf{map}} is a measure used in information
retrieval. It expresses how well the true classification can be retrieved in
the first results of the classifier. We define two variants of
\ac{map}, one (MAPc) to state how well all records for a specific class are
retrieved, the other (MAPs) to asses how well the correct class is retrieved
for a specific sample. The first is defined for $n$ samples and $k$ classes,
with $\vect{Y}=\vect{y}_1,\dots,\vect{y}_k$ and $\vect{\hat
  Y}=\vect{\hat y}_1,\dots,\vect{\hat y}_k$ the ground truth and
prediction $n\times k$ matrices. The formula is:
\begin{equation*}
  MAPc(\vect{Y}, \vect{\hat Y})\equiv
  \frac{1}{k}\sum_{c=1}^{k}AveP(\vect{y}_c, \vect{\hat y}_c),
\end{equation*}
where $AveP$ is the average precision for class $c$:
\begin{equation*}
  AveP(\vect{y}, \vect{\hat y}) \equiv
  \frac{1}{\sum_{i=1}^k 1(y_i)}\sum_{j=1}^k P_j(\vect{y}, \vect{\hat y})\cdot 1(y_{\sigma_{\vect{\hat y}}(j)}),
\end{equation*}
where $1(y)$ is an indicator
function that is $1$ for the elements classified positively, $0$
otherwise. $\sigma_{\vect{\hat y}}(j)$ is a function that returns the
  index in $\vect{\hat y}$ of the $j$-th element in the ordered
  version of $\vect{\hat y}$ . $P_j$ is defined as:
\begin{equation*}
P_j(\vect{y}, \vect{\hat y}) \equiv \frac{1}{j}\sum_{c=1}^j
1(y_{\sigma_{\vect{\hat y}}(c)}).
\end{equation*}

MAPs is defined like MAPc, but on the transposed classification
matrices
\begin{equation*}
  MAPs(\vect{Y}, \vect{\hat Y})\equiv
  MAPc(\vect{Y}^T, \vect{\hat Y}^T)
\end{equation*}

\subsection{Precision} is defined for $n$ samples and binary
classifications as:
\begin{equation}\label{eq:precision}
P(\vect{y}, \vect{\hat y}) \equiv \frac{\sum_{s=1}^n 1(\hat
  y_s \text{ and }y_s)}{\sum_{s=1}^n 1(\hat y_s)}.
\end{equation}
It expresses the ratio of correct positive predictions over all the
positive predictions.

\subsection{Recall} conversely, is defined as:
\begin{equation}\label{eq:recall}
R(\vect{y}, \vect{\hat y}) \equiv \frac{\sum_{s=1}^n 1(\hat
  y_s \text{ and }y_s)}{\sum_{s=1}^n 1(y_s)},
\end{equation}
and it is the ratio of correct predicted positive over all the positive
classes.

\subsection{F1-score} is the harmonic mean of precision and recall,
combining the two measures:
\begin{equation*}
F_1(\vect{y}, \vect{\hat y}) \equiv 
2\frac{P(\vect{y}, \vect{\hat y})\cdot R(\vect{y}, \vect{\hat y})}
{P(\vect{y}, \vect{\hat y})+R(\vect{y}, \vect{\hat y})}.
\end{equation*}

Precision, recall, and thus $F_1$ score are defined only for binary
classifiers. In order to use those metrics in a multi-class
classification problem it is possible to average the measures for the
different classes. We considered different methodologies of averaging:
\begin{description}
  \item[micro] averaging is performed flattening the array of truth
    and prediction of the different classes and then appling the
    scoring formula;
  \item[macro] average is performed calculating the metrics on the
    single classes and then averaging them:
    \begin{equation*}
      \frac{1}{k}\sum_{c=1}^k S(\vect{y}_c, \vect{\hat y}_c);
    \end{equation*}
  \item[weighted] average uses the normalized number of samples for
    each class in order to give a weight to them:
    \begin{equation*}
      \frac{1}{\sum_{i=1}^k|\vect{\hat y}_i|}\sum_{c=1}^k|\vect{\hat y}_c|\cdot S(\vect{y}_c, \vect{\hat y}_c).
    \end{equation*}
\end{description}

Micro average considers all the samples equally, regardless of the
representativeness of classes in the dataset. Macro average takes
into account the unbalancement and it is more sensible to few
represented classes. Precision, recall, and $F_1$ score are
equal to the accuracy when micro averaged in a multiclass
environment. 

\subsection{ROC curve} is a graph of \emph{true positive rate} versus
\emph{false positive rate} with the change of the classifier threshold. The
true positive rate is equal to the recall defined in
\cref{eq:recall}. Conversely the false positive rate is defined as:
\begin{equation}\label{eq:fpr}
FPR(\vect{y}, \vect{\hat y}) \equiv \frac{\sum_{s=1}^n 1(\hat
  y_s \text{ and not }y_s)}{\sum_{s=1}^n 1(\text{not }y_s)}.
\end{equation}

ROC curves start from $(0,0)$ and end in $(1,1)$. The area under
the curve can be used as a metric for the classifier, a perfect
classifier has an area of $1$.

The curves can be calculated only for binary classifiers. Like for the
precision, recall and $F_1$ score, it is possible to generalise them to
multiclass problems averaging micro or macro.

\subsection{Precision-recall curve} is a graph of precision
(\cref{eq:precision}) versus 
recall (\cref{eq:recall}) with the change of the classifier
threshold. The curves start from $(0,1)$ and end in $(1,0)$. A perfect
classifier has an area under the curve of $1$.

Also precision-recall curves can be calculated only for binary
classifiers. In order to generalise them to multiclass problem it is
necessary to micro or macro average.




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
